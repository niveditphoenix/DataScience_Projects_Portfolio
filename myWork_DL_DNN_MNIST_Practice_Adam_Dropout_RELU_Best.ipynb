{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data' , one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = mnist.train.images\n",
    "trainY = mnist.train.labels\n",
    "\n",
    "testX = mnist.test.images\n",
    "testY = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in [trainX, trainY, testX, testY]:\n",
    "    i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.0000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.09800</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.089200</td>\n",
       "      <td>0.095800</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.097400</td>\n",
       "      <td>0.100900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.29733</td>\n",
       "      <td>0.317219</td>\n",
       "      <td>0.304235</td>\n",
       "      <td>0.301344</td>\n",
       "      <td>0.2976</td>\n",
       "      <td>0.285046</td>\n",
       "      <td>0.294331</td>\n",
       "      <td>0.303713</td>\n",
       "      <td>0.296516</td>\n",
       "      <td>0.301211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3           4  \\\n",
       "count  10000.00000  10000.000000  10000.000000  10000.000000  10000.0000   \n",
       "mean       0.09800      0.113500      0.103200      0.101000      0.0982   \n",
       "std        0.29733      0.317219      0.304235      0.301344      0.2976   \n",
       "min        0.00000      0.000000      0.000000      0.000000      0.0000   \n",
       "25%        0.00000      0.000000      0.000000      0.000000      0.0000   \n",
       "50%        0.00000      0.000000      0.000000      0.000000      0.0000   \n",
       "75%        0.00000      0.000000      0.000000      0.000000      0.0000   \n",
       "max        1.00000      1.000000      1.000000      1.000000      1.0000   \n",
       "\n",
       "                  5             6             7             8             9  \n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000  \n",
       "mean       0.089200      0.095800      0.102800      0.097400      0.100900  \n",
       "std        0.285046      0.294331      0.303713      0.296516      0.301211  \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testY).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.003\n",
    "\n",
    "n_features = trainX.shape[1]\n",
    "n_classes = trainY.shape[1]\n",
    "\n",
    "# No of Batches\n",
    "batch_size = 100\n",
    "\n",
    "# No of epochs\n",
    "training_epoch = 40\n",
    "\n",
    "# Logs Path and Model Name\n",
    "logs_path = r\"C:\\Users\\Nivedit\\tmp\\mnist\\DNN\\AdamOptimizer\\V2\"\n",
    "model_name = \"mnist.ckpt\"\n",
    "\n",
    "# Hidden Layers\n",
    "K = 200\n",
    "L = 100\n",
    "M = 60\n",
    "N = 30\n",
    "\n",
    "# Define traiing and test keep%\n",
    "training_keep = 0.75\n",
    "test_keep = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Inputs\"):\n",
    "    X = tf.placeholder(dtype = tf.float32, shape=[None, n_features], name = \"X-Input\")\n",
    "    Y_actual = tf.placeholder(dtype = tf.float32, shape=[None, n_classes], name = \"Y-Input\")\n",
    "    pkeep = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using RELU as Activation Function across all Layers but NOT on FINAL Layer since we are using SOFTMAX to consider proabilities for each class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Layer-1\"):\n",
    "    W1 = tf.Variable(tf.truncated_normal([n_features, K], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.zeros([K]))\n",
    "    #Y1 = tf.nn.sigmoid(tf.add(tf.matmul(X,W1),b1))\n",
    "    Y1 = tf.nn.relu(tf.add(tf.matmul(X,W1),b1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Layer-2\"):\n",
    "    W2 = tf.Variable(tf.truncated_normal([K, L], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.zeros([L]))\n",
    "    #Y2 = tf.nn.sigmoid(tf.add(tf.matmul(Y1,W2),b2))\n",
    "    Y2 = tf.nn.relu(tf.add(tf.matmul(Y1,W2),b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Layer-3\"):\n",
    "    W3 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\n",
    "    b3 = tf.Variable(tf.zeros([M]))\n",
    "    #Y3 = tf.nn.sigmoid(tf.add(tf.matmul(Y2,W3), b3))\n",
    "    Y3 = tf.nn.relu(tf.add(tf.matmul(Y2,W3), b3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Layer-4\"):\n",
    "    W4 = tf.Variable(tf.truncated_normal([M,N], stddev=0.1))\n",
    "    b4 = tf.Variable(tf.zeros(N))\n",
    "    #Y4 = tf.nn.sigmoid(tf.add(tf.matmul(Y3,W4), b4))\n",
    "    Y4 = tf.nn.relu(tf.add(tf.matmul(Y3,W4), b4))\n",
    "    Y4d = tf.nn.dropout(Y4, pkeep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction as in** FINAL LAYER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Output\"):\n",
    "    W5 = tf.Variable(tf.truncated_normal([N, n_classes], stddev=0.1))\n",
    "    b5 = tf.Variable(tf.zeros(n_classes))\n",
    "    Y_Logit = tf.matmul(Y4d,W5) + b5\n",
    "    Y_pred = tf.nn.softmax(tf.add(tf.matmul(Y4d,W5), b5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Loss\"):\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=Y_Logit, labels=Y_actual)\n",
    "    cross_entropy = tf.reduce_mean(cross_entropy)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Output\"):\n",
    "    #train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "    # Using Adam Optimizer\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Accuracy\"):\n",
    "    prediction = tf.argmax(Y_pred, 1, name=\"Predict\")\n",
    "    check = tf.equal(prediction, tf.argmax(Y_actual, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(check, tf.float32), name=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss Logging and Accuracy Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_loss = tf.summary.scalar(\"Training_loss\", cross_entropy)\n",
    "training_accuray = tf.summary.scalar(\"Training_accuracy\", accuracy)\n",
    "\n",
    "test_loss = tf.summary.scalar(\"Test_loss\", cross_entropy)\n",
    "test_accuracy = tf.summary.scalar(\"Test_accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saver to save the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Graph with batch count of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is:  0\n",
      "Test Accuracy is:  0.9499\n",
      "Epoch is:  5\n",
      "Test Accuracy is:  0.9752\n",
      "Epoch is:  10\n",
      "Test Accuracy is:  0.9774\n",
      "Epoch is:  15\n",
      "Test Accuracy is:  0.9787\n",
      "Epoch is:  20\n",
      "Test Accuracy is:  0.9731\n",
      "Epoch is:  25\n",
      "Test Accuracy is:  0.9785\n",
      "Epoch is:  30\n",
      "Test Accuracy is:  0.978\n",
      "Epoch is:  35\n",
      "Test Accuracy is:  0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Nivedit\\\\tmp\\\\mnist\\\\DNN\\\\AdamOptimizer\\\\V2\\\\mnist.ckpt'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Creating Log Writer Object\n",
    "    writer = tf.summary.FileWriter(logs_path, graph = tf.get_default_graph())\n",
    "    \n",
    "    # Batch Count\n",
    "    batch_count = int(trainX.shape[0]/batch_size)\n",
    "    \n",
    "    # training cycles as epoch\n",
    "    for epoch in range(training_epoch):\n",
    "        \n",
    "        # number of epochs in 1 batch\n",
    "        for i in range(batch_count):\n",
    "            batch_x = trainX[i*batch_size : i*batch_size + batch_size]\n",
    "            batch_y = trainY[i*batch_size : i*batch_size + batch_size]\n",
    "            \n",
    "            train_model, acc, loss = sess.run([train_op, training_accuray, training_loss], \n",
    "                                              feed_dict = {X:batch_x , Y_actual:batch_y, pkeep:training_keep})\n",
    "            \n",
    "            # Log Training Accuracy and Loss\n",
    "            writer.add_summary(acc, epoch*batch_count + i)\n",
    "            writer.add_summary(loss, epoch*batch_count + i)\n",
    "        \n",
    "        # Log Test Accuracy and Loss\n",
    "        acc,loss = sess.run([test_accuracy, test_loss], feed_dict = {X:testX, Y_actual:testY, pkeep:test_keep})\n",
    "        writer.add_summary(acc, epoch*batch_count + batch_count)\n",
    "        writer.add_summary(loss, epoch*batch_count + batch_count)\n",
    "        \n",
    "        if epoch %5 == 0:\n",
    "            print(\"Epoch is: \", epoch)\n",
    "            print(\"Test Accuracy is: \", accuracy.eval(feed_dict={X:testX, Y_actual:testY, pkeep:test_keep}))\n",
    "        \n",
    "    # Save the model\n",
    "    saver.save(sess, os.path.join(logs_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
